{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Smile Detection using Convolutional Neural Networks\n",
    "Date: 2019-06-17 9:30\n",
    "Category: Deep Learning\n",
    "Tags: CNN\n",
    "Slug: dadjokesforsmiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smile detection applications are countless from activating a camera shutter automatically, enhancing human-robot interaction, to being incorporated into assistive communication devices for people with disabilities. Using deep learning convolutional neural network algorithms, a smile detection algorithm with an accuracy of 89% was achieved!\n",
    "\n",
    "As a project I created [Dad Jokes for Smiles](https://github.com/audreymychan/djsmile), a Flask-powered web application to showcase a smile detection algorithm trained using convolutional neural networks. It takes input from a user's webcam and returns predictions on how much they're smiling! It also provides random dad jokes from *icanhazdadjoke*'s API for fun and because why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "Motivation for the project came from a previous program I wrote to detect smiles 7 years ago where the algorithm was based on my naive knowledge of what it means for someone to be smiling. For example, I detected the mouth using edge detection then identified smiles based on color pixel changes (red vs white). \n",
    "\n",
    "### Problem\n",
    "Of course this was highly sensitive to noise (i.e. lighting, face orientation, etc). Nowadays with more computing power, we can simply use machine learning to do a better job and remove human bias! Convolutional Neural Networks (CNNs) can find new variables we didn't even know matter and their weights to improve our model. Hypothetically, it might even determine how much ones's crow's feet around the eye impact smile predictions.\n",
    "\n",
    "## Demo Video\n",
    "Click the screenshot below to see a demo.\n",
    "\n",
    "[![App screen recording](https://img.youtube.com/vi/g3G3tXIf4fk/0.jpg)](https://www.youtube.com/watch?v=g3G3tXIf4fk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Process\n",
    "\n",
    "### <img style=\"float:left; margin:0px 10px 10px 0;\" src=\"./images/scraper.png\" alt=\"scraper\" width=\"30\"/> Web Scraping\n",
    "Total of 8,600 images were scraped from Getty Images based on searches for \"smile\" and \"no smile\".\n",
    "\n",
    "<img style=\"float:left; margin:2px 5px 0px 0;\" src=\"./images/smile_example_1.jpg\" alt=\"smile_example_1\" width=\"100\"/>\n",
    "<img style=\"float:left; margin:2px 5px 0px 0;\" src=\"./images/smile_example_2.jpg\" alt=\"smile_example_2\" width=\"100\"/>\n",
    "<img style=\"float:left; margin:2px 5px 0px 0;\" src=\"./images/no_smile_example_1.jpg\" alt=\"no_smile_example_1\" width=\"100\"/>\n",
    "<img style=\"float:left; margin:2px 5px 0px 0;\" src=\"./images/no_smile_example_2.jpg\" alt=\"no_smile_example_2\" width=\"100\"/>\n",
    "<br/><br/><br/>\n",
    "\n",
    "Refer to `getty_scraper.py` and images folder on my [GitHub](https://github.com/audreymychan/djsmile)\n",
    "\n",
    "**Tools used:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `requests`\n",
    "- `BeautifulSoup`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img style=\"float:left; margin:0px 10px 10px 0;\" src=\"./images/edit.png\" alt=\"edit\" width=\"30\"/> Image Pre-processing\n",
    "Images collected were then:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cropped with a bounding box around faces detected\n",
    "- converted to grayscale\n",
    "- resized down to 100 x 100 px\n",
    "- convert into an array\n",
    "- normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image dataset was split into a training set and a test set (for model evaluation).\n",
    "\n",
    "Random transformations and normalization operations (i.e. adjusting for rotation and lighting) were configured on the training set to create more variation for the model to learn.\n",
    "\n",
    "<img style=\"float:left; margin:2px 5px 0px 0;\" src=\"./images/grey_crop_smile_1.jpg\" alt=\"grey_crop_smile_1\" width=\"100\"/>\n",
    "<img style=\"float:left; margin:2px 5px 0px 0;\" src=\"./images/grey_crop_smile_2.jpg\" alt=\"grey_crop_smile_2\" width=\"100\"/>\n",
    "<img style=\"float:left; margin:2px 5px 0px 0;\" src=\"./images/grey_crop_no_smile_1.jpg\" alt=\"grey_crop_no_smile_1\" width=\"100\"/>\n",
    "<img style=\"float:left; margin:2px 5px 0px 0;\" src=\"./images/grey_crop_no_smile_2.jpg\" alt=\"grey_crop_no_smile_2\" width=\"100\"/>\n",
    "<br/><br/><br/><br/>\n",
    "\n",
    "*Image to array example (each pixel ranging from 0 to 255):*\n",
    "\n",
    "<img style=\"float:left;\" src=\"./images/img_to_array.gif\" alt=\"img_to_array\" width=\"100\"/>\n",
    "<br/><br/><br/><br/>\n",
    "\n",
    "Refer to `cnn_model_training.ipynb` and images folder on my [GitHub](https://github.com/audreymychan/djsmile)\n",
    "\n",
    "**Tools used:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `PIL` - Image\n",
    "- `face_recognition`\n",
    "- `tensorflow.keras` - array_to_img, img_to_array, ImageDataGenerator, to_categorical\n",
    "- `sklearn` - MinMaxScaler, LabelEncoder, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img style=\"float:left; margin:0px 10px 10px 0;\" src=\"./images/training.png\" alt=\"training\" width=\"30\"/> Training the Model - Convolutional Neural Network (CNN)\n",
    "A convolutional neural network model was trained using the images.\n",
    "\n",
    "Refer to `cnn_model_training.ipynb` for layers and weights used in the CNN on my [GitHub](https://github.com/audreymychan/djsmile)\n",
    "\n",
    "**Tools used:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tensorflow.keras` - Sequential, Input, Conv2D, MaxPooling2D, Dropout, Dense, Flatten, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img style=\"float:left; margin:0px 10px 10px 0;\" src=\"./images/save.png\" alt=\"save\" width=\"30\"/> Saving the Model\n",
    "The CNN model and weights learned were saved and can be used to predict smile versus no smile on any new image coming from the app. The model was saved under `my_model.h5` and MinMaxScaler under `scaler.save`.\n",
    "\n",
    "Refer to `cnn_model_training.ipynb` and models folder on my [GitHub](https://github.com/audreymychan/djsmile)\n",
    "\n",
    "**Tools used:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `sklearn` - joblib\n",
    "- `tensorflow.keras` - save, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img style=\"float:left; margin:0px 10px 10px 0;\" src=\"./images/internet.png\" alt=\"internet\" width=\"30\"/> Flask App\n",
    "The app can be generated with the following files:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `app.py`: main application to run\n",
    "- `camera.py`: contains Camera object to capture live video feed and `get_frame()` function return image with a bounding box marked around the face and text indicating smile probabilities\n",
    "- `generate_joke.py`: contains `get_joke()` function to access *icanhazdadjoke*'s API and return a random generated joke\n",
    "- `smile_recognition.py`: contains `predict_smile()` function which takes in an image frame and returns smile predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<img src=\"./images/dad_black.png\" alt=\"Dad black icon\" width=\"30\"/> \n",
    "## Future Work\n",
    "- Publish the app online\n",
    "    - Make sure it's compatible on all platforms, devices, and camera settings\n",
    "- Improve the CNN model\n",
    "    - Some ideas for improvements include:\n",
    "        - Relabel dataset to ensure images are correctly categorized as smile or no smile\n",
    "        - Optimizing neural network parameters\n",
    "        - Increasing dataset\n",
    "        - Using larger image sizes\n",
    "        - Using RGB images instead of grayscale\n",
    "- (nice to have) Improve UX/UI of the application\n",
    "\n",
    "*Keep smiling... it makes people wonder what you are up to.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
